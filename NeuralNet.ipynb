{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import random\n",
    "import matplotlib.pyplot as plt # to visualize only\n",
    "from skimage.transform import resize, rescale\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_x_pd = pd.read_csv(\"./data/processed_x.csv\", delimiter=\",\", header = None) # load from processed images\n",
    "# train_x = train_x.values # dataframe to numpy ndarray\n",
    "# train_x = train_x.astype(np.float32)\n",
    "# train_x /= 255 # normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_y_pd = pd.read_csv(\"./data/train_y.csv\", delimiter = \",\", header = None)\n",
    "# train_y = (train_y.values).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can see resized 28x28 image\n",
    "def plotter(images, labels, start):\n",
    "    plt.figure(figsize=(20,4))\n",
    "    for index, (image, label) in enumerate(zip(images[start:start+5], labels[start:start+5])):\n",
    "        plt.subplot(1, 5, index + 1)\n",
    "        im = np.reshape(image, (28,28))\n",
    "        plt.imshow(im, cmap= 'gray')\n",
    "        plt.title('Training: %i\\n' % label, fontsize = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x288 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plotter(x, data_y, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Prepare Data for Neural Net ###\n",
    "\n",
    "data_x = data_x_pd.head(5000).values.astype(np.float32)\n",
    "data_y = np.array(list(map(int, data_y_pd.head(5000)[0].tolist())), dtype=object)\n",
    "\n",
    "# Normalize x values\n",
    "data_x /= 255\n",
    "\n",
    "num_rows = 28\n",
    "num_cols = num_rows\n",
    "\n",
    "x = np.zeros((data_x.shape[0], num_rows*num_cols))\n",
    "\n",
    "scale = num_rows/64\n",
    "\n",
    "for i in range(len(x)):\n",
    "    img = data_x[i].reshape(64,64)\n",
    "    image = rescale(img, scale, mode = 'reflect')\n",
    "    image = image.reshape(28**2)\n",
    "    x[i] = image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate sigmoid of input\n",
    "\n",
    "def sigmoid(z):\n",
    "    return 1.0/(1.0 + np.exp(-z))\n",
    "\n",
    "# calculate derivative of sigmoid at the input\n",
    "def sigmoid_prime(z):\n",
    "    return sigmoid(z)*(1-sigmoid(z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(object):\n",
    "\n",
    "    def __init__(self, dims):\n",
    "        # dims contains number of neurons in each layer\n",
    "        # first index is dimension of input (eg. size of image)\n",
    "        # last layer is dimension of output (10)\n",
    "        # length of dims is # of layers of network\n",
    "        # biases and weights are intialized randomly using Gaussian dist 9 (mean 0, sd 1)\n",
    "        self.num_layers = len(dims)\n",
    "        self.dims = dims\n",
    "        self.biases = [np.random.randn(y, 1) for y in dims[1:]]\n",
    "        self.weights = [np.random.randn(y, x)\n",
    "                        for x, y in zip(dims[:-1], dims[1:])]\n",
    "    \n",
    "    # calculate value out of first hidden layer\n",
    "    def feedforward(self, a):\n",
    "        for b, w in zip(self.biases, self.weights):\n",
    "            a = sigmoid(np.dot(w, a)+b)\n",
    "        return a\n",
    "\n",
    "    def SGD(self, training_data, epochs, mini_batch_size, eta,\n",
    "            valid_data, progress = None):\n",
    "        \"\"\"Train the neural network using mini-batch stochastic\n",
    "        gradient descent.  The ``training_data`` is a list of tuples\n",
    "        ``(x, y)`` representing the training inputs and the desired\n",
    "        outputs.  The other non-optional parameters are\n",
    "        self-explanatory.  If ``test_data`` is provided then the\n",
    "        network will be evaluated against the test data after each\n",
    "        epoch, and partial progress printed out.  This is useful for\n",
    "        tracking progress, but slows things down substantially.\"\"\"\n",
    "        if valid_data: n_valid = len(valid_data)\n",
    "        n = len(training_data)\n",
    "        for j in range(epochs):\n",
    "            random.shuffle(training_data)\n",
    "            self.update_mini_batch(training_data, eta)\n",
    "            \n",
    "            valid_score = self.evaluate(valid_data)\n",
    "#             print(\"Epoch {0}: {1} / {2}\".format(\n",
    "#                j, valid_score, n_valid))\n",
    "            if progress is not None:\n",
    "                progress[j] = valid_score\n",
    "            \n",
    "        return valid_score\n",
    "        \n",
    "    def update_mini_batch(self, mini_batch, eta):\n",
    "        \"\"\"Update the network's weights and biases by applying\n",
    "        gradient descent using backpropagation to a single mini batch.\n",
    "        The ``mini_batch`` is a list of tuples ``(x, y)``, and ``eta``\n",
    "        is the learning rate.\"\"\"\n",
    "        nabla_b = [np.zeros(b.shape) for b in self.biases]\n",
    "        nabla_w = [np.zeros(w.shape) for w in self.weights]\n",
    "        for x, y in mini_batch:\n",
    "            delta_nabla_b, delta_nabla_w = self.backprop(x, y)\n",
    "            nabla_b = [nb+dnb for nb, dnb in zip(nabla_b, delta_nabla_b)]\n",
    "            nabla_w = [nw+dnw for nw, dnw in zip(nabla_w, delta_nabla_w)]\n",
    "        self.weights = [w-(eta/len(mini_batch))*nw\n",
    "                        for w, nw in zip(self.weights, nabla_w)]\n",
    "        self.biases = [b-(eta/len(mini_batch))*nb\n",
    "                       for b, nb in zip(self.biases, nabla_b)]\n",
    "\n",
    "    def backprop(self, x, y):\n",
    "        \"\"\"Return a tuple ``(nabla_b, nabla_w)`` representing the\n",
    "        gradient for the cost function C_x.  ``nabla_b`` and\n",
    "        ``nabla_w`` are layer-by-layer lists of numpy arrays, similar\n",
    "        to ``self.biases`` and ``self.weights``.\"\"\"\n",
    "        nabla_b = [np.zeros(b.shape) for b in self.biases]\n",
    "        nabla_w = [np.zeros(w.shape) for w in self.weights]\n",
    "        \n",
    "        # feedforward\n",
    "        activation = x\n",
    "        activations = [x] # list to store all the activations, layer by layer\n",
    "        zs = [] # list to store all the z vectors, layer by layer\n",
    "        for b, w in zip(self.biases, self.weights):\n",
    "            z = np.dot(w, activation)+b\n",
    "            zs.append(z)\n",
    "            activation = sigmoid(z)\n",
    "            activations.append(activation)\n",
    "            \n",
    "        # backward pass\n",
    "        delta = self.cost_derivative(activations[-1], y) * \\\n",
    "            sigmoid_prime(zs[-1])\n",
    "        nabla_b[-1] = delta\n",
    "        nabla_w[-1] = np.dot(delta, activations[-2].transpose())\n",
    "\n",
    "        # Note that the variable l in the loop below is used a little\n",
    "        # differently to the notation in Chapter 2 of the book.  Here,\n",
    "        # l = 1 means the last layer of neurons, l = 2 is the\n",
    "        # second-last layer, and so on.  It's a renumbering of the\n",
    "        # scheme in the book, used here to take advantage of the fact\n",
    "        # that Python can use negative indices in lists.\n",
    "        for l in range(2, self.num_layers):\n",
    "            z = zs[-l]\n",
    "            sp = sigmoid_prime(z)\n",
    "            delta = np.dot(self.weights[-l+1].transpose(), delta) * sp\n",
    "            nabla_b[-l] = delta\n",
    "            nabla_w[-l] = np.dot(delta, activations[-l-1].transpose())\n",
    "        return (nabla_b, nabla_w)\n",
    "\n",
    "    def evaluate(self, test_data):\n",
    "        \"\"\"Return the number of test inputs for which the neural\n",
    "        network outputs the correct result. Note that the neural\n",
    "        network's output is assumed to be the index of whichever\n",
    "        neuron in the final layer has the highest activation.\"\"\"\n",
    "        test_results = [(np.argmax(self.feedforward(x)), y)\n",
    "                        for (x, y) in test_data]  \n",
    "        return sum(int(x == y) for (x, y) in test_results)\n",
    "\n",
    "    def cost_derivative(self, output_activations, y):\n",
    "        \"\"\"Return the vector of partial derivatives \\partial C_x /\n",
    "        \\partial a for the output activations.\"\"\"\n",
    "        return (output_activations-y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f8469cedf60>"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4wLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvFvnyVgAAEFNJREFUeJzt3WuMVeW9x/Hf32kFQaJchsmAXIohhjslW2OCgEepQVJF35j6ouEkptSkJqdJX9TYF8eX5uS0jS9OmlAlhZNqPbFViZoekRwlRkRHEMQicnEUCMIgXkBQbv/zYhbNqLP+a9y3tWee7yeZzMz67cV+2Ppj7b2fvdZj7i4A6bmk7AEAKAflBxJF+YFEUX4gUZQfSBTlBxJF+YFEUX4gUZQfSNT3mnln48aN86lTpzbzLoGkdHd369ixYzaQ29ZUfjNbJulhSW2SHnH3h6LbT506VV1dXbXcJYBApVIZ8G2rftpvZm2S/kvSrZJmSrrbzGZW++cBaK5aXvNfJ2mvu+939zOS/iJpRX2GBaDRain/REkH+vx+MNv2NWa2ysy6zKyrp6enhrsDUE8Nf7ff3Ve7e8XdK+3t7Y2+OwADVEv5D0ma1Of3q7JtAAaBWsr/hqTpZvYDM7tU0k8kra/PsAA0WtVTfe5+zszuk/S/6p3qW+Pu79RtZBgSPv7446r3HT16dJhfcgmfUatFTfP87v68pOfrNBYATcQ/nUCiKD+QKMoPJIryA4mi/ECiKD+QqKaez4/GOHnyZG528ODBcN+jR4/WdN+nT58O8507d+Zm58+fD/ddsGBBmM+cGZ9E2tnZmZuZDeiU9yGNIz+QKMoPJIryA4mi/ECiKD+QKMoPJIqpvhZw/PjxMN+3b1+Yb926NTfbvn17uO+BAwfCvEjRVF809gsXLoT7zpgxI8yXL18e5itW5F9ScsqUKeG+KeDIDySK8gOJovxAoig/kCjKDySK8gOJovxAopjnr4PolFpJ2rVrV5i//PLLYV40Vx/N8xfN43/xxRdhPnbs2DAfM2ZMmEdz+UWfb3jhhRfCvGjs0XLwkyZNys2kNC4LPvT/hgD6RfmBRFF+IFGUH0gU5QcSRfmBRFF+IFE1zfObWbekE5LOSzrn7pV6DKoVReetv/rqq+G+69atC/PXXnstzHt6esL8xIkTuVlbW1u477XXXhvmt9xyS5gXnRf/+eef52abNm0K933ppZfCfPfu3WEefU5g2rRp4b6zZs0K86Fw6e96fMjnX9z9WB3+HABNxNN+IFG1lt8lvWBmb5rZqnoMCEBz1Pq0/wZ3P2Rm4yVtMLN33f1rL+SyfxRWSdLkyZNrvDsA9VLTkd/dD2Xfj0p6StJ1/dxmtbtX3L3S3t5ey90BqKOqy29mI81s1MWfJd0iKX9VRgAtpZan/R2SnsqmPL4n6TF3/3tdRgWg4aouv7vvlzSvjmMplbuH+ZYtW3KzRx55JNy31vPSR40aFeY33nhjbjZvXvyfaOHChWG+ePHiMB8/fnyYnzp1KjebPXt2uG/RXPqLL74Y5s8991xuNnHixHDfousUTJgwIcwHA6b6gERRfiBRlB9IFOUHEkX5gURRfiBRXLo7U7Rc9LZt23KzV155Jdy3aBnrSiU+E3rJkiVV53PmzAn3Lbo09/Dhw8O8yIgRI3Kzoqm+mTNnhnnRKcEffPBBblZ0OfTDhw+HOVN9AAYtyg8kivIDiaL8QKIoP5Aoyg8kivIDiWKePxOdeipJn3zySW5WdErujBkzwnzlypVhfuedd4Z5dFpt2ZeYPnfuXG62c2d87Zdo6XGp+PMT0TLbl156abhvUT4UcOQHEkX5gURRfiBRlB9IFOUHEkX5gURRfiBRzPNnis7v3rFjR2725ZdfhvsWnZd+/fXXh3lHR0eYlymax5fiJbqLliaPLpcuFX82I1qGe+7cueG+nZ2dYT4UcOQHEkX5gURRfiBRlB9IFOUHEkX5gURRfiBRhfP8ZrZG0o8lHXX32dm2MZKekDRVUreku9w9/4T3QeDdd98N8127duVmZ86cCfctOt8/ulaAJH311VdhPmzYsDCvRTRPLxXPxUdz+Rs3bgz3PXHiRJgXnXO/YMGC3KxoafJx48aF+VAwkCP/nyQt+8a2+yVtdPfpkjZmvwMYRArL7+6bJB3/xuYVktZmP6+VdEedxwWgwap9zd/h7hfXM/pIUut+/hRAv2p+w8/dXZLn5Wa2ysy6zKyrp6en1rsDUCfVlv+ImXVKUvb9aN4N3X21u1fcvdLe3l7l3QGot2rLv17SxUvOrpT0TH2GA6BZCstvZo9L2izpGjM7aGb3SHpI0o/MbI+kpdnvAAaRwnl+d787J7q5zmMpVdFLkijfu3dvuG90LQBJevrpp8P87NmzYT558uQwjxSdj1809sceeyzMN2/enJsVzeMX/b2nTJkS5pVKJTebPn16uG8K+IQfkCjKDySK8gOJovxAoig/kCjKDySKS3dn5s2bF+ZLly7NzQ4dOhTu293dHeZPPPFEmEenE0vSVVddFeaRCxcuhPnu3bvDvGgqsOjy2rUouqT51VdfnZulcMpuEY78QKIoP5Aoyg8kivIDiaL8QKIoP5Aoyg8kinn+TNHpobfddltuVnTZ7w8//DDMjxw5EuYbNmwI86FqxIgRYT5x4sQwb+WlzVsBR34gUZQfSBTlBxJF+YFEUX4gUZQfSBTlBxLFPH/GzML8mmuuyc1uv/32cN+iJbhr/ZxAZNq0aWEe/b0kaeTIkWH+/vvvh/l7772XmxVdunvs2LFhPn/+/DAv+ruljiM/kCjKDySK8gOJovxAoig/kCjKDySK8gOJKpznN7M1kn4s6ai7z862PSjpZ5J6sps94O7PN2qQreCyyy7LzRYvXhzuO3r06DDfvn17mEdz5UVmz54d5nPnzg3z06dPh/mTTz4Z5vv27QvzSNFnDIrWKxg/fnzV952CgRz5/yRpWT/bf+/u87OvIV18YCgqLL+7b5J0vAljAdBEtbzmv8/MdpjZGjOLn9cCaDnVlv8Pkq6WNF/SYUm/zbuhma0ysy4z6+rp6cm7GYAmq6r87n7E3c+7+wVJf5R0XXDb1e5ecfdKe3t7teMEUGdVld/MOvv8eqeknfUZDoBmGchU3+OSbpQ0zswOSvp3STea2XxJLqlb0s8bOEYADVBYfne/u5/NjzZgLC2tra0tNyuaby56uVN0Xvpnn30W5pGizxiMGTMmzLds2RLmRefknzp1KjcrmsefM2dOmM+aNSvMEeMTfkCiKD+QKMoPJIryA4mi/ECiKD+QKC7d3QTDhg0L887OzpryWrh7mB84cCDMiy7dfebMmdysaBqy6HTjohwxjvxAoig/kCjKDySK8gOJovxAoig/kCjKDySKef7EFV1ae9u2bWF+5MiRqu/7kkviY0/RKb/R5dRRjCM/kCjKDySK8gOJovxAoig/kCjKDySK8gOJYp5/iCuah3/22WfDfP369WF++PDh7zymi4rm8S+//PKq/2wU48gPJIryA4mi/ECiKD+QKMoPJIryA4mi/ECiCuf5zWySpHWSOiS5pNXu/rCZjZH0hKSpkrol3eXunzRuqKhG0Tz866+/HuZ79uwJ86I1CTo6OnKzm2++Odx3wYIFYY7aDOTIf07Sr9x9pqTrJf3CzGZKul/SRnefLmlj9juAQaKw/O5+2N23Zj+fkLRL0kRJKyStzW62VtIdjRokgPr7Tq/5zWyqpB9K2iKpw90vPqf8SL0vCwAMEgMuv5ldLumvkn7p7p/3zbx3wbd+F30zs1Vm1mVmXT09PTUNFkD9DKj8ZvZ99Rb/z+7+t2zzETPrzPJOSUf729fdV7t7xd0r7e3t9RgzgDooLL+ZmaRHJe1y99/1idZLWpn9vFLSM/UfHoBGGcgpvQsl/VTS22b2VrbtAUkPSfofM7tH0geS7mrMEFHk7NmzudmxY8fCfT/99NMwHz58eJgvXLgwzJctW5abLVq0KNx3zpw5YY7aFJbf3V+RZDlxPFELoGXxCT8gUZQfSBTlBxJF+YFEUX4gUZQfSBSX7h4Cjh8/npvt2LEj3Hf37t1hfsUVV4T50qVLw/zee+/NzYqW2O79fBkahSM/kCjKDySK8gOJovxAoig/kCjKDySK8gOJYp5/EDh//nyY79+/PzfbvHlz1ftK0rx588J8woQJYT5ixIgwR3k48gOJovxAoig/kCjKDySK8gOJovxAoig/kCjm+QeBkydPhnl0Tn53d3e476RJk8L8pptuCvP58+eHOVoXR34gUZQfSBTlBxJF+YFEUX4gUZQfSBTlBxJVOM9vZpMkrZPUIcklrXb3h83sQUk/k9ST3fQBd3++UQNFvtGjR+dmixYtCvcdN25cmN96661hPmPGjDBH6xrIh3zOSfqVu281s1GS3jSzDVn2e3f/z8YND0CjFJbf3Q9LOpz9fMLMdkma2OiBAWis7/Sa38ymSvqhpC3ZpvvMbIeZrTGzfp97mtkqM+sys66enp7+bgKgBAMuv5ldLumvkn7p7p9L+oOkqyXNV+8zg9/2t5+7r3b3irtX2tvb6zBkAPUwoPKb2ffVW/w/u/vfJMndj7j7eXe/IOmPkq5r3DAB1Fth+a13qdRHJe1y99/12d7Z52Z3StpZ/+EBaJSBvNu/UNJPJb1tZm9l2x6QdLeZzVfv9F+3pJ83ZIQoXCZ7yZIluVnRVNyoUaPCfPz48WHe1tYW5mhdA3m3/xVJ/S2Uzpw+MIjxCT8gUZQfSBTlBxJF+YFEUX4gUZQfSBSX7h4CrrzyyqoypI0jP5Aoyg8kivIDiaL8QKIoP5Aoyg8kivIDiTJ3b96dmfVI+qDPpnGSjjVtAN9Nq46tVcclMbZq1XNsU9x9QNfLa2r5v3XnZl3uXiltAIFWHVurjktibNUqa2w87QcSRfmBRJVd/tUl33+kVcfWquOSGFu1Shlbqa/5AZSn7CM/gJKUUn4zW2Zmu81sr5ndX8YY8phZt5m9bWZvmVlXyWNZY2ZHzWxnn21jzGyDme3Jvucv0dv8sT1oZoeyx+4tM1te0tgmmdn/mdk/zOwdM/u3bHupj10wrlIet6Y/7TezNknvSfqRpIOS3pB0t7v/o6kDyWFm3ZIq7l76nLCZLZZ0UtI6d5+dbfsPScfd/aHsH87R7v7rFhnbg5JOlr1yc7agTGfflaUl3SHpX1XiYxeM6y6V8LiVceS/TtJed9/v7mck/UXSihLG0fLcfZOk49/YvELS2uznter9n6fpcsbWEtz9sLtvzX4+IeniytKlPnbBuEpRRvknSjrQ5/eDaq0lv13SC2b2ppmtKnsw/ejIlk2XpI8kdZQ5mH4UrtzcTN9YWbplHrtqVryuN97w+7Yb3H2BpFsl/SJ7etuSvPc1WytN1wxo5eZm6Wdl6X8q87GrdsXreiuj/IckTerz+1XZtpbg7oey70clPaXWW334yMVFUrPvR0sezz+10srN/a0srRZ47Fppxesyyv+GpOlm9gMzu1TSTyStL2Ec32JmI7M3YmRmIyXdotZbfXi9pJXZzyslPVPiWL6mVVZuzltZWiU/di234rW7N/1L0nL1vuO/T9JvyhhDzrimSdqefb1T9tgkPa7ep4Fn1fveyD2SxkraKGmPpBcljWmhsf23pLcl7VBv0TpLGtsN6n1Kv0PSW9nX8rIfu2BcpTxufMIPSBRv+AGJovxAoig/kCjKDySK8gOJovxAoig/kCjKDyTq/wGz6Bypua8qtgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x[45].reshape(num_rows, num_cols), cmap = 'gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=5)\n",
    "kf.get_n_splits(x)\n",
    "\n",
    "num_epochs = 2000\n",
    "\n",
    "layer_dims = [[784,100,10],[784,50,10],[784,100,50, 10],\n",
    "              [784,200,10]]\n",
    "\n",
    "learning_rates = [1.0, 4.0, 8.0]\n",
    "\n",
    "accuracies = []\n",
    "progress_per_epoch = np.zeros((len(layer_dims)*len(learning_rates), num_epochs))\n",
    "# print(progress_per_epoch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for train_index, valid_index in kf.split(x):\n",
    "    \n",
    "    train_x, valid_x = x[train_index], x[valid_index]\n",
    "    train_y, valid_y = data_y[train_index], data_y[valid_index]\n",
    "    \n",
    "    # vectorize training targets\n",
    "    for i in range(len(train_y)):\n",
    "        vect = np.zeros((10,1), dtype=object)\n",
    "        vect[train_y[i]] = 1\n",
    "        train_y[i] = vect.astype(float)\n",
    "    \n",
    "    # reshape and zip train and valid\n",
    "    training_inputs = [np.reshape(x,(train_x.shape[1],1)) \n",
    "                       for x in train_x]\n",
    "    valid_inputs = [np.reshape(x,(valid_x.shape[1],1)) for x in valid_x]\n",
    "    training_data = list(zip(training_inputs, train_y))\n",
    "    valid_data = list(zip(valid_inputs, valid_y))\n",
    "\n",
    "    \n",
    "    pos = 0 \n",
    "    \n",
    "    for i, dim in enumerate(layer_dims):\n",
    "        for j, lr in enumerate(learning_rates):\n",
    "            print(\"NN dimensions: {}, learning rate: {}, \".format(dim, lr) )\n",
    "            average_score = 0\n",
    "            \n",
    "        \n",
    "            neural_net = Network(dim)\n",
    "            valid_score = neural_net.SGD(training_data, num_epochs, 784, lr, valid_data, progress_per_epoch[pos])\n",
    "            average_score += valid_score\n",
    "            accuracies.append(average_score/len(valid_x))\n",
    "            print(average_score)\n",
    "            pos += 1\n",
    "             \n",
    "    \n",
    "# \n",
    "#        neural_net = Network([num_rows*num_cols, 100, 10])\n",
    "#     valid_score = neural_net.SGD(training_data, num_epochs, 784, 4.0, valid_data)\n",
    "#     average_score += valid_score\n",
    "#     average_score /= len(valid_x)\n",
    "    break\n",
    "\n",
    "# print average_accuracy / 5.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=5)\n",
    "kf.get_n_splits(x)\n",
    "\n",
    "num_epochs = 2500\n",
    "\n",
    "\n",
    "layer_dims2 = [[784, 50, 100, 10], [784, 70, 30, 70, 10]]\n",
    "\n",
    "\n",
    "learning_rate = 4.0\n",
    "\n",
    "accuracies2 = []\n",
    "progress_per_epoch2 = np.zeros((len(layer_dims2), num_epochs))\n",
    "\n",
    "# print(progress_per_epoch2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN dimensions: [784, 50, 100, 10], learning rate: 4.0, \n",
      "356\n",
      "NN dimensions: [784, 70, 30, 70, 10], learning rate: 4.0, \n",
      "612\n"
     ]
    }
   ],
   "source": [
    "for train_index, valid_index in kf.split(x):\n",
    "    \n",
    "    train_x, valid_x = x[train_index], x[valid_index]\n",
    "    train_y, valid_y = data_y[train_index], data_y[valid_index]\n",
    "    \n",
    "    # vectorize training targets\n",
    "    for i in range(len(train_y)):\n",
    "        vect = np.zeros((10,1), dtype=object)\n",
    "        vect[train_y[i]] = 1\n",
    "        train_y[i] = vect.astype(float)\n",
    "    \n",
    "    # reshape and zip train and valid\n",
    "    training_inputs = [np.reshape(x,(train_x.shape[1],1)) \n",
    "                       for x in train_x]\n",
    "    valid_inputs = [np.reshape(x,(valid_x.shape[1],1)) for x in valid_x]\n",
    "    training_data = list(zip(training_inputs, train_y))\n",
    "    valid_data = list(zip(valid_inputs, valid_y))\n",
    "\n",
    "    \n",
    "    pos = 0 \n",
    "    \n",
    "    for i, dim in enumerate(layer_dims2):\n",
    "        print(\"NN dimensions: {}, learning rate: {}, \".format(dim, learning_rate) )\n",
    "       \n",
    "        average_score = 0\n",
    "\n",
    "        neural_net = Network(dim)\n",
    "        valid_score = neural_net.SGD(training_data, num_epochs, 784, learning_rate, valid_data, progress_per_epoch2[pos])\n",
    "        average_score += valid_score\n",
    "        accuracies2.append(average_score/len(valid_x))\n",
    "        print(average_score)\n",
    "        pos += 1\n",
    "\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.461, 0.369, 0.433, 0.624, 0.628, 0.619, 0.718, 0.772, 0.536, 0.109, 0.337, 0.109]\n"
     ]
    }
   ],
   "source": [
    "print(accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 71.  85.  88. ... 460. 460. 461.]\n",
      " [103. 121. 122. ... 369. 369. 369.]\n",
      " [ 81. 107. 107. ... 434. 425. 433.]\n",
      " ...\n",
      " [139. 129. 130. ... 109. 109. 109.]\n",
      " [108. 102. 102. ... 338. 339. 337.]\n",
      " [126. 124. 123. ... 109. 109. 109.]]\n"
     ]
    }
   ],
   "source": [
    "print(progress_per_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(accuracies)\n",
    "df.to_csv(\"./data/nn_accuracies.csv\", header = False, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(progress_per_epoch)\n",
    "df.to_csv(\"./data/nn_progress.csv\", header = False, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[353. 354. 353. 354. 353. 354. 353. 354. 353. 354. 353. 354. 353. 354.\n",
      " 353. 354. 353. 354. 353. 354. 353. 355. 353. 355. 352. 355. 352. 355.\n",
      " 352. 355. 352. 355. 352. 355. 352. 355. 352. 355. 352. 355. 352. 355.\n",
      " 352. 355. 352. 355. 352. 355. 352. 355. 352. 355. 352. 355. 352. 355.\n",
      " 352. 355. 353. 355. 353. 355. 353. 355. 353. 355. 353. 355. 353. 355.\n",
      " 353. 355. 353. 355. 353. 355. 353. 355. 353. 355. 353. 355. 353. 355.\n",
      " 353. 355. 353. 355. 353. 355. 353. 355. 353. 355. 353. 355. 353. 355.\n",
      " 353. 355. 353. 355. 353. 355. 353. 355. 353. 355. 353. 355. 353. 355.\n",
      " 354. 356. 354. 356. 354. 356. 354. 356. 354. 356. 354. 356. 354. 356.\n",
      " 354. 356. 354. 356. 354. 356. 354. 356. 354. 356. 354. 356. 354. 356.\n",
      " 354. 356. 354. 356. 354. 356. 354. 356. 354. 356. 354. 356. 354. 356.\n",
      " 354. 356. 354. 356. 354. 356. 354. 356. 354. 356. 354. 356. 354. 356.\n",
      " 354. 356. 354. 356. 354. 356. 353. 356. 353. 356. 353. 356. 353. 356.\n",
      " 353. 356. 353. 356. 353. 356. 353. 356. 353. 356. 353. 356. 353. 356.\n",
      " 354. 356. 354. 356. 354. 356. 354. 356. 354. 356. 354. 356. 354. 356.\n",
      " 354. 356. 354. 356. 354. 357. 355. 357. 355. 357. 355. 357. 355. 357.\n",
      " 355. 357. 355. 357. 355. 357. 355. 357. 355. 357. 355. 357. 355. 357.\n",
      " 355. 357. 355. 357. 355. 357. 355. 357. 355. 357. 355. 357. 355. 357.\n",
      " 355. 357. 355. 357. 355. 357. 355. 357. 355. 357. 355. 357. 355. 357.\n",
      " 355. 357. 356. 357. 356. 357. 356. 357. 356. 357. 356. 357. 356. 357.\n",
      " 356. 357. 356. 357. 356. 357. 356. 357. 356. 357. 356. 357. 356. 357.\n",
      " 356. 357. 356. 357. 356. 357. 356. 356. 356. 356. 356. 356. 356. 356.\n",
      " 356. 356. 356. 356. 356. 356. 356. 356. 356. 356. 356. 356. 356. 356.\n",
      " 356. 356. 356. 356. 356. 356. 356. 356. 356. 356. 356. 356. 356. 356.\n",
      " 356. 356. 356. 356. 356. 356. 356. 356. 356. 356. 356. 356. 356. 356.\n",
      " 356. 356. 356. 356. 356. 356. 356. 356. 356. 356. 356. 356. 356. 356.\n",
      " 356. 356. 356. 356. 356. 356. 356. 356. 356. 356. 356. 356. 356. 356.\n",
      " 356. 356. 356. 356. 356. 356. 356. 356. 356. 356. 356. 356. 356. 356.\n",
      " 356. 356. 356. 356. 356. 356. 356. 355. 356. 355. 356. 355. 356. 355.\n",
      " 356. 355. 356. 355. 356. 355. 356. 355. 356. 355. 356. 355. 356. 355.\n",
      " 356. 355. 356. 355. 356. 355. 356. 355. 356. 355. 356. 355. 356. 355.\n",
      " 356. 355. 356. 355. 356. 355. 356. 355. 356. 355. 356. 355. 356. 355.\n",
      " 356. 355. 356. 355. 356. 355. 356. 355. 356. 355. 356. 355. 356. 355.\n",
      " 356. 355. 356. 355. 356. 355. 356. 355. 356. 355. 356. 355. 356. 355.\n",
      " 356. 355. 356. 355. 356. 355. 356. 355. 356. 356. 356. 356. 356. 356.\n",
      " 356. 356. 356. 356. 356. 356. 356. 356. 356. 356.]\n"
     ]
    }
   ],
   "source": [
    "print(progress_per_epoch2[0, 2000:])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
